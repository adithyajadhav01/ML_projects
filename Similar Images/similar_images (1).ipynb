{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44de511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6739cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e998c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7a2419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4738\n"
     ]
    }
   ],
   "source": [
    "file_path = os.listdir('/Users/adithyaram/Downloads/dataset')\n",
    "print(len(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70946e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(file_path, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdf3d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Images: 4027\n",
      "Number of Testing Images: 711\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Training Images:\",len(train_data))\n",
    "print(\"Number of Testing Images:\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec2d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagetoarray(file_array):\n",
    "    images_array = np.empty((len(file_array), 224, 224, 3), dtype=np.float32)\n",
    "    \n",
    "    for i,path in enumerate(file_array):\n",
    "        image_path = ('/Users/adithyaram/Downloads/dataset/' + path)\n",
    "        image = Image.open(image_path)\n",
    "        resized_image = image.resize((224, 224))\n",
    "        resized_image = np.array(resized_image)\n",
    "        images_array[i] = resized_image.astype('float32')/255\n",
    "        \n",
    "    return images_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6306e4be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training dataset: (4027, 224, 224, 3)\n",
      "Length of test dataset: (711, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = imagetoarray(train_data)\n",
    "print(\"Length of training dataset:\",train_data.shape)\n",
    "test_data = imagetoarray(test_data)\n",
    "print(\"Length of test dataset:\",test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02380b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3), padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same'))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')) \n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='same')) \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')) \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid')) \n",
    "    \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))        \n",
    "    model.add(Conv2D(512, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(256, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))              \n",
    "    model.add(Conv2D(128, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))            \n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((2, 2)))  \n",
    "    model.add(Conv2D(3, kernel_size=(3, 3), kernel_regularizer = tf.keras.regularizers.L2(0.001), activation='relu', padding='same'))\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a0983a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 14, 14, 512)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 28, 28, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 256)       1179904   \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSamplin  (None, 56, 56, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 56, 56, 128)       295040    \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSamplin  (None, 112, 112, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 112, 112, 64)      73792     \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSamplin  (None, 224, 224, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 224, 224, 3)       1731      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10180867 (38.84 MB)\n",
      "Trainable params: 10180867 (38.84 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = encoder_decoder_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c90007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f6a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2c2fa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 [==============================] - 928s 7s/step - loss: 0.5964\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - 47305s 378s/step - loss: 0.2103\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - 7052s 48s/step - loss: 0.1252\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - 841s 7s/step - loss: 0.0841\n",
      "Epoch 5/10\n",
      " 90/126 [====================>.........] - ETA: 1:13:44 - loss: 0.0641"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, train_data, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def feature_extraction(model, data, layer):\n",
    "\n",
    "    encoded = K.function([model.layers[0].input],[model.layers[layer].output])\n",
    "    encoded_array = encoded([data])[0]\n",
    "    pooled_array = encod= ed_array.max(axis=-1)\n",
    "    return encoded_array\n",
    "\n",
    "encoded = feature_extraction(model,train_data[:10],9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203006dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "values = tsne.fit_transform(encoded) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e9b4ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3674646434.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/bx/jlpx0hb91sncsn279dvq7f2m0000gn/T/ipykernel_19220/3674646434.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for k in K:\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "K = [4, 5, 6, 7]\n",
    "\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters = k, random_state=0).fit(encoded)\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    plt.figure(figsize=(10,5)) \n",
    "    plt.subplot(1,1,1)\n",
    "    plt.scatter(values[:,0], values[:,1], c= kmeans.labels_.astype(float), s=50, alpha=0.5)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], c=None, s=50)\n",
    "    plt.show()\n",
    "    for row in range(k): \n",
    "        iter=0\n",
    "        plt.figure(figsize=(13,3))\n",
    "        for i,iterator in enumerate(labels):\n",
    "            if iterator == row:\n",
    "                img_path = '/Users/adithyaram/Downloads/dataset/' + lips[i]\n",
    "                img = Image.open(img_path)\n",
    "                plot_(img,\"\",\"\",1,6,iter+1,\"cluster=\"+str(row),\"\",\"\",\"\",True)\n",
    "                iter+=1\n",
    "            if iter>=5: break\n",
    "        plt.show()\n",
    "    print() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
